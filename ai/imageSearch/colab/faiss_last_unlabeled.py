# -*- coding: utf-8 -*-
"""faiss-last-unlabeled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CQXAK9UOD5x9wyMlg6Qsnhw3Dd4zVO2F

### 사전 세팅 및 드라이브 연결
"""

!pip install --upgrade pip
!pip install transformers datasets faiss-cpu -q
# !pip install transformers datasets faiss-gpu -q

from google.colab import drive
drive.mount('/content/drive')

"""### Import"""

from transformers import AutoFeatureExtractor, AutoModel
from datasets import load_dataset, concatenate_datasets, load_from_disk
from PIL import Image
import numpy as np
import torch
from torchvision import transforms

"""### Train"""

# ===== 사전학습 모델 세팅 및 특징 추출기 세팅
model_ckpt = "google/vit-base-patch16-224"
BATCH = 128

extractor = AutoFeatureExtractor.from_pretrained(model_ckpt)
model = AutoModel.from_pretrained(model_ckpt)
hidden_dim = model.config.hidden_size

import os
import shutil

# 복사할 폴더 경로
source_folder = '/content/drive/MyDrive/faiss/faiss_dataset/train'
# 대상 폴더 경로
destination_folder = '/content/drive/MyDrive/faiss/faiss_dataset/unlabeled_train'

# 대상 폴더가 없으면 생성
if not os.path.exists(destination_folder):
    os.makedirs(destination_folder)

# source_folder 내의 모든 하위 폴더를 순회
for folder_name in os.listdir(source_folder):
    folder_path = os.path.join(source_folder, folder_name)

    if os.path.isdir(folder_path):  # 폴더인지 확인
        # 폴더 내의 파일들을 순회
        for filename in os.listdir(folder_path):
            source_path = os.path.join(folder_path, filename)
            destination_path = os.path.join(destination_folder, filename)

            # 파일인 경우만 복사
            if os.path.isfile(source_path):
                shutil.copy(source_path, destination_path)

# ===== 데이터셋 설정
dataset = load_dataset("imagefolder", data_dir='/content/drive/MyDrive/faiss/faiss_dataset/unlabeled_train')

from PIL import Image
import torch

def extract_embeddings(example):
    # example 이미지 데이터가 파일 경로인 경우 불러오기
    if isinstance(example['image'], str):
        image = Image.open(example['image'])
    else:
        image = example['image']

    # 특징 추출기를 통해 이미지 전처리
    inputs = extractor(images=image, return_tensors="pt")
    outputs = model(**inputs)
    features = outputs.last_hidden_state[:, 0].detach().cpu().numpy()

    return {'embeddings': features.squeeze()}

# 데이터셋에 임베딩 추출 함수 적용
unlabeled_dataset = dataset['train'].map(extract_embeddings, batched=True, batch_size=BATCH)

# 임베딩 데이터 디스크에 저장
unlabeled_dataset.save_to_disk('/content/drive/MyDrive/processed_unlabeled_images/')

# Faiss 인덱스 생성 및 저장
unlabeled_dataset.add_faiss_index(column='embeddings')
unlabeled_dataset.save_faiss_index('embeddings', '/content/drive/MyDrive/unlabeled_images_index.faiss')

"""### Test: Image Search"""

def get_neighbors(query_image, top_k=10):
    qi_embedding = model(**extractor(query_image, return_tensors="pt"))   # 쿼리 이미지 특징 추출
    qi_embedding = qi_embedding.last_hidden_state[:, 0].detach().numpy().squeeze()  # 쿼리 이미지의 임베딩 추출
    scores, retrieved_examples = unlabeled_dataset.get_nearest_examples('embeddings', qi_embedding, k=top_k)
    return scores, retrieved_examples  # 유사도 점수와 인덱스 반환

def image_grid(imgs, rows, cols):
    w,h = imgs[0].size
    grid = Image.new('RGB', size=(cols*w, rows*h))
    for i, img in enumerate(imgs): grid.paste(img, box=(i%cols*w, i//cols*h))
    return grid

# load query_image from input path
query_image = Image.open('/content/drive/MyDrive/faiss/faiss_dataset/test/130.jpg')
query_image

scores, retrieved_examples = get_neighbors(query_image, top_k = 20)
images = [query_image]
images.extend(retrieved_examples["image"])

image_grid(images, 2, round(len(images)/2))

# load query_image from input path
query_image = Image.open('/content/drive/MyDrive/faiss/faiss_dataset/test/172.jpg')
query_image

scores, retrieved_examples = get_neighbors(query_image, top_k = 20)
images = [query_image]
images.extend(retrieved_examples["image"])

image_grid(images, 2, round(len(images)/2))

# load query_image from input path
query_image = Image.open('/content/drive/MyDrive/faiss/faiss_dataset/test/312.jpg')
query_image

scores, retrieved_examples = get_neighbors(query_image, top_k = 20)
images = [query_image]
images.extend(retrieved_examples["image"])

image_grid(images, 2, round(len(images)/2))

# load query_image from input path
query_image = Image.open('/content/drive/MyDrive/faiss/faiss_dataset/test/530.jpg')
query_image

scores, retrieved_examples = get_neighbors(query_image, top_k = 20)
images = [query_image]
images.extend(retrieved_examples["image"])

image_grid(images, 2, round(len(images)/2))

# load query_image from input path
query_image = Image.open('/content/drive/MyDrive/faiss/faiss_dataset/test/531.jpg')
query_image

scores, retrieved_examples = get_neighbors(query_image, top_k = 20)
images = [query_image]
images.extend(retrieved_examples["image"])

image_grid(images, 2, round(len(images)/2))

# load query_image from input path
query_image = Image.open('/content/drive/MyDrive/faiss/faiss_dataset/test/629.jpg')
query_image

scores, retrieved_examples = get_neighbors(query_image, top_k = 20)
images = [query_image]
images.extend(retrieved_examples["image"])

image_grid(images, 2, round(len(images)/2))

